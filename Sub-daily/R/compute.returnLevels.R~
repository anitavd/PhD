######################################################################################
#
# Runs the final BHM with selected covariates and computes return level including 
# 95% confidence interval. These are written out in seperate textfiles (vectors)
#
# Anita Verpe Dyrrdal, met.no, May-2013
#
######################################################################################

rm(list=ls())
library(SpatialExtremes)
library(extRemes)
library(ismev)
library(ncdf)
#library(spBayes)
#library(geoR)
#library(met.no.REB)
#source("/home/anitavd/PhD/Sub-daily/R/latent.AVD.R")
#source("/home/anitavd/PhD/Sub-daily/R/map.latent.AVD.R")

loc <- c()
scale <- c()
shape.est <- c()
east <- c()
north <- c()
lon <- c()
lat <- c()
stnr <- c()
elev <- c()
M5 <- c()
M5.3h <- c()
loc.3h <- c()
tam.jja <- c()
summerRR <- c()
distSea <- c()
data.am <- matrix(NA,46,80)
data.am[,1] <- seq(1967,2012)
j <- 1
no.obs <- 0   #length of the longest series
t<-2

TabID <- as.numeric(as.matrix(read.table("/home/anitavd/scripts/TabID.txt",header=TRUE)))

#Read files with observations
tipping.stations <- list.files("~/PhD/Sub-daily/data/tipping/",pattern = "hourly_AM.txt", full.names=F)
geonor.stations <- list.files("~/PhD/Sub-daily/data/geonor/",pattern = "hourly_AM.txt", full.names=F)
all.stations <- c(tipping.stations,geonor.stations)
no.stations <- length(all.stations)

for (i in 1:no.stations) {
print(i)
	file <- all.stations[i]
	station <- try(read.table(paste("~/PhD/Sub-daily/data/tipping/",file,sep=""),header=F,skip=3),silent=T)
	if(class(station)=="try-error") station <- try(read.table(paste("/home/anitavd/PhD/Sub-daily/data/geonor/",file,sep=""),header=F,skip=3),silent=T)
	colnames(station) <- c("STNR","EAST","NORTH","LON","LAT","YEAR","RR_1")
	station$RR_1[which(station$RR_1 >= 50)] = NA
	data <- station$RR_1[!is.na(station$RR_1)]

	if(length(data) > 9) {

		first.year <- station$YEAR[1]
		last.year <- tail(station$YEAR,1)
		idx1 <- which(data.am[,1]==first.year)
		idx2 <- which(data.am[,1]==last.year)
		for (l in idx1:idx2) {
			try(data.am[l,t] <- station$RR_1[which(station$YEAR==data.am[l,1])],silent=T)
		}
		t <- t+1


		loc <- rbind(loc,gev.fit(data)$mle[1])
		scale <- rbind(scale,gev.fit(data)$mle[2]) 
		shape.est <- rbind(shape.est,gev.fit(data)$mle[3])  

		stnr <- rbind(stnr, station$STNR[1])
		east <- rbind(east, station$EAST[1])
		north <- rbind(north, station$NORTH[1])
		lon <- rbind(lon, station$LON[1])
		lat <- rbind(lat, station$LAT[1])
		#data.am[1:length(data),j] <- data
		no.obs <- max(no.obs,length(which(!is.na(data))))

		#Extract elevation from climate grid
		x = round((station$EAST - (-75000 + 500)) / 1000, digits = 0) + 1
		y = round((station$NORTH - (6450000 + 500)) / 1000, digits = 0) + 1
		point = (1550 - y) * 1195 + (x - 1) + 1
		filename=sprintf("/vol/klimagrid/senorge/dem1.bil")
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		elev.point <- readBin(con, integer(), size=2, n=1)	# [m] 
		close(con)

		#If grid cell is outside the grid, find a grid cell nearby that is within the grid
		if(elev.point==0) {
			offset <- c(1, -1, 1195, -1195, 1196, -1196, 1194, -1194)
			for (k in 1:8) {
				con=file(filename,open="rb")
				seek(con, where = ((point + offset[k] - 1) * 2), origin = "start")   # Set position
				elev.point <- readBin(con, integer(), size=2, n=1)	# [m] 
				close(con)
				if(elev.point>0) {
					point <- point + offset[k]				
					break()
				}
			}
		}
		elev <- rbind(elev,as.numeric(elev.point))			

		#Extract M5(24h) computed from the climate grid
		filename=sprintf("~/PhD/Sub-daily/Covariates/M5_RRuncor.bil")
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		M5 <- rbind(M5,readBin(con, integer(), size=2, n=1))	# [mm] 
		close(con)

		#M5 for 3-hour precipitation
		filename<-"~/PhD/Sub-daily/Covariates/M5_rr3.bil"
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		M5.3h <- rbind(M5.3h,readBin(con,integer(),size=2,n=1))
		close(con)

		#M5 for 3-hour precipitation
		filename<-"~/PhD/Sub-daily/Covariates/loc.RR3.bil"
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		loc.3h <- rbind(loc.3h,readBin(con,integer(),size=2,n=1))
		close(con)

		#Summer temperature
		filename<-"~/PhD/Sub-daily/Covariates/tam_jja.bil"
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		tam.jja <- rbind(tam.jja,(readBin(con,integer(),size=2,n=1)-2730)/10)
		close(con)

		#Area dominated by summer precipitation (1)
		filename<-"~/PhD/Sub-daily/Covariates/area_summerPrecip.bil"
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		summerRR <- rbind(summerRR,readBin(con,integer(),size=2,n=1))
		close(con)

		#Distance from coast
		filename<-"~/PhD/Sub-daily/Covariates/distsea_km.bil"
		con=file(filename,open="rb")
		seek(con, where = ((point - 1) * 2), origin = "start")   # Set position
		distSea <- rbind(distSea,readBin(con,integer(),size=2,n=1))
		close(con)

		j <- j+1
		
	}

}

no.sites <- length(loc)

data.am <- data.am[,1:(no.sites+1)]

#Extend series to no.obs by generating a GEV series with the same parameters as original series.
#for (i in 2:(no.sites+1)) {

#	no.na <- length(which(is.na(data.am[,i])))
#	add <- round(gen.gev(gevmle(data.am[,i][which(!is.na(data.am[,i]))]),no.na),digits=1)

#	no.toohigh <- length(which(add>(max(data.am[,i],na.rm=T)+10) | add<0))
#	if(no.toohigh > 0) add[which(add>(max(data.am[,i],na.rm=T)+10) | add<0)] <- round(gen.gev(gevmle(data.am[,i][which(!is.na(data.am[,i]))]),no.toohigh),digits=1)

#	data.am[,i][which(is.na(data.am[,i]))] <- add

#}

shape <- rep(0.10,no.sites)

coord <- cbind(east,north)
colnames(coord) <- c("east","north")
east.norm <- (east-mean(east,na.rm=T))/apply(east,2,sd)
north.norm <- (north-mean(north,na.rm=T))/apply(north,2,sd)
coord.norm <- cbind(east.norm, north.norm)
colnames(coord.norm) <- c("east","north")

elev[which(elev == -1)] = NA
M5[which(M5 == -1)] = NA
M5.3h[which(M5.3h == -1)] = NA
loc.3h[which(loc.3h == -1)] = NA
loc.3h <- loc.3h/100

#Bayesian spatial model
#Assume that the processes for each GEV parameters are mutually independent Gaussian processes.

#2nd layer

#Spatial linear model for the mean of the latent process, link to covariates
#Normalize covariates
cov1 <- (north-mean(north,na.rm=T))/apply(north,2,sd)
cov2 <- east.norm
cov3 <- (tam.jja-mean(tam.jja,na.rm=T))/apply(tam.jja,2,sd)
cov4 <- (elev-mean(elev,na.rm=T))/apply(elev,2,sd)
cov5 <- (distSea-mean(distSea,na.rm=T))/apply(distSea,2,sd)
cov6 <- (M5-mean(M5,na.rm=T))/apply(M5,2,sd)
cov7 <- (M5.3h-mean(M5.3h,na.rm=T))/apply(M5.3h,2,sd)
cov8 <- (loc.3h-mean(loc.3h,na.rm=T))/apply(loc.3h,2,sd)
#cov9 <- (MAP-mean(MAP,na.rm=T))/apply(MAP,2,sd)
#cov10 <- (MSP-mean(MSP,na.rm=T))/apply(MSP,2,sd)
#cov11 <- (wetDays-mean(wetDays,na.rm=T))/apply(wetDays,2,sd)
cov12 <- cov2*summerRR

loc.form <- y ~ cov2 + cov3 + cov4 + cov7
scale.form <- y ~ cov3 + cov7
shape.form <- y ~ 1    #constant

#range in meters
#s11 <- 2
#s12 <- 20
#s21 <- 2
#s22 <- 4
#r11 <- 2
#r12 <- 8000
#r21 <- 2
#r22 <- 8000

#Normalized
s11 <- 2
s12 <- 6
s21 <- 2
s22 <- 2
r11 <- 2
r12 <- 2
r21 <- 1.5
r22 <- 1.5

#####################################################################################################################################################
#3rd layer

hyper <- list()
hyper$sills <- list(loc = c(s11,s12), scale = c(s21,s22), shape = c(2,1))  #inverse gamma prior
hyper$ranges <- list(loc = c(r11,r12), scale = c(r21,r22), shape = c(2,1))  #gamma prior, uninformative	
hyper$smooths <- list(loc = c(1,1/3), scale = c(1,1/3), shape = c(2,1))	 #gamma prior, uninformative
hyper$betaMeans <- list(loc = c(5,0,0,0,0), scale = c(2,0,0), shape = 0.1)	 #multivariate normal distribution, uninformative 
 
hyper$betaIcov <- list(loc = solve(diag(c(100,100,100,100,100))),scale=solve(diag(c(100,100,100))),shape=solve(diag(c(0.0000000001), 1, 1)))  #covariance matrix

prop <- list(gev = c(1.2, 0.08, 0.1), ranges = c(0.7, 0.8, 0.7), smooths = c(0,0,0))
 
start <- list(sills = c(5,2,2), ranges = c(1,1,10), smooths= c(1,1,1), beta = list(loc = c(5,1,1,1,1), scale = c(2,1,1),shape = c(0.1)))  

marg.cov <- cbind(cov2,cov3,cov4,cov8)
colnames(marg.cov) <- c("cov2","cov3","cov4","cov7")

#Run model, Markov chain. data should be a matrix with no NA's. marg.cov???
mc <- latent(data=data.am[,-1], coord.norm, marg.cov = marg.cov, loc.form = loc.form, scale.form = scale.form,shape.form = shape.form, hyper = hyper, prop = prop, start = start, n = 1000, burn.in= 300, thin = 15)   #RETURN THIS LIST! n=300000, burn.in=5000, thin=30 (Davison...)

sink(paste("~/PhD/Sub-daily/Results/mc_mod2.txt",sep=""))
print(mc)
sink()

#Les in aktuelle covariater og forleng radene til 1550. Husk Ã¥ normaliser! NA --> 0 ?
no.cov <- 4

con <- open.ncdf("~/PhD/Sub-daily/Covariates/east.nc")
lon <- get.var.ncdf(con,"east_raster")
close(con)
lon <- lon[TabID]
lon[which(is.na(lon))] = 0
dim(lon) <- c(length(lon),1)
cov2 <- rep(0,1550*1195)
cov2[TabID] <- (lon-mean(lon,na.rm=T))/apply(lon,2,sd)

filename<-"~/PhD/Sub-daily/Covariates/tam_jja.bil"
con=file(filename,open="rb")
JJAtemp <- readBin(con,integer(),size=2,n=1550*1195)
close(con)
JJAtemp <- JJAtemp[TabID]
JJAtemp[JJAtemp==-1] = NA
JJAtemp <- (JJAtemp-2730)/10
JJAtemp[which(is.na(JJAtemp))] = 0
dim(JJAtemp) <- c(length(JJAtemp),1)
cov3 <- rep(0,1550*1195)
cov3[TabID] <- (JJAtemp-mean(JJAtemp,na.rm=T))/apply(JJAtemp,2,sd)

filename=sprintf("/vol/klimagrid/senorge/dem1.bil")
con=file(filename,open="rb")
elev <- readBin(con,integer(),size=2,n=1550*1195)
close(con)
elev <- elev[TabID]
elev[elev==-1] = NA
elev[which(is.na(elev))] = 0
dim(elev) <- c(length(elev),1)
cov4 <- rep(0,1550*1195)
cov4[TabID] <- (elev-mean(elev,na.rm=T))/apply(elev,2,sd)

filename<-"~/PhD/Sub-daily/Covariates/M5_rr3.bil"
con=file(filename,open="rb")
M5.3h <- readBin(con,integer(),size=2,n=1550*1195)
close(con)
M5.3h <- M5.3h[TabID]
M5.3h[M5.3h==-1] = NA
M5.3h[which(is.na(M5.3h))] = 0
dim(M5.3h) <- c(length(M5.3h),1)
cov7 <- rep(0,1550*1195)
cov7[TabID] <- (M5.3h-mean(M5.3h,na.rm=T))/apply(M5.3h,2,sd)

dim(cov2) <- c(1195,1550)
dim(cov3) <- c(1195,1550)
dim(cov4) <- c(1195,1550)
dim(cov7) <- c(1195,1550)

#Make the grid 1200*1600 so that we can separate into 400*400 squares and run map.latent for each 12 squares.
#Put the results together to a full map (remove added rows and columns) in the end. Check for consistency in the borders.
for (i in 1:5) {
	cov2 <- rbind(cov2,rep(0,1550))
	cov3 <- rbind(cov3,rep(0,1550))
	cov4 <- rbind(cov4,rep(0,1550))
	cov7 <- rbind(cov7,rep(0,1550))
}
for (i in 1:50) {
	cov2 <- cbind(cov2,rep(0,1200))
	cov3 <- cbind(cov3,rep(0,1200))
	cov4 <- cbind(cov4,rep(0,1200))
	cov7 <- cbind(cov7,rep(0,1200))
}


#cov <- array(NA,c(1550,1550,no.cov))
#cov[,,1] <- cov1
#cov[,,2] <- cov3
#cov[,,3] <- cov4
#cov[,,4] <- cov7

cov <- array(0,c(400,400,no.cov))
cov[,,1] <- cov2[1:400,1:400]
cov[,,2] <- cov3[1:400,1:400]
cov[,,3] <- cov4[1:400,1:400]
cov[,,4] <- cov7[1:400,1:400]

#
#legg in riktige covariater!
dimnames(cov) <- list(NULL,NULL,c("cov2","cov3","cov4","cov7"))

#x.grid <- y.grid <- seq(1,1550)
x.grid <- y.grid <- seq(1,400)
res <- map.latent(mc,x.grid,y.grid,covariates=cov,param="quant", ret.per=25)
print(round(res$post.sum,1)*10,paste("~/PhD/Sub-daily/Results/mod2_mean_M",rep.per,".txt",sep=""))   #1 decimal
print(round(res$ci.low,1)*10,paste("~/PhD/Sub-daily/Results/mod2_CIlow_M",rep.per,".txt",sep=""))
print(round(res$ci.up,1)*10,paste("~/PhD/Sub-daily/yResults/mod2_CIup_M",rep.per,".txt",sep=""))






